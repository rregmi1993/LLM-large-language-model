{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM/mrCor7GAl0B7+YZi7In",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rregmi1993/LLM-large-language-model/blob/main/LangChain_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuzQXOCtrAlf",
        "outputId": "b88d2695-41dd-4c22-b262-457ec9cc698c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 1)) (0.28.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 2)) (0.0.348)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 3)) (2.2.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 5)) (0.5.2)\n",
            "Requirement already satisfied: llmx in /usr/local/lib/python3.10/dist-packages (from -r ./requirement.txt (line 6)) (0.0.15a0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai->-r ./requirement.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->-r ./requirement.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai->-r ./requirement.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (2.0.23)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.12 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (0.0.12)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r ./requirement.txt (line 2)) (8.2.3)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client->-r ./requirement.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client->-r ./requirement.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client->-r ./requirement.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from pinecone-client->-r ./requirement.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from pinecone-client->-r ./requirement.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->-r ./requirement.txt (line 5)) (2023.6.3)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from llmx->-r ./requirement.txt (line 6)) (5.6.3)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (from llmx->-r ./requirement.txt (line 6)) (4.37)\n",
            "Requirement already satisfied: google.auth in /usr/local/lib/python3.10/dist-packages (from llmx->-r ./requirement.txt (line 6)) (2.17.3)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from llmx->-r ./requirement.txt (line 6)) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r ./requirement.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r ./requirement.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r ./requirement.txt (line 1)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r ./requirement.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->-r ./requirement.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirement.txt (line 2)) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirement.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->-r ./requirement.txt (line 2)) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain->-r ./requirement.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain->-r ./requirement.txt (line 2)) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->pinecone-client->-r ./requirement.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r ./requirement.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r ./requirement.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->-r ./requirement.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r ./requirement.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx->-r ./requirement.txt (line 6)) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2.0,>=1.8 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx->-r ./requirement.txt (line 6)) (1.9.1)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere->llmx->-r ./requirement.txt (line 6)) (6.11.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx->-r ./requirement.txt (line 6)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx->-r ./requirement.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google.auth->llmx->-r ./requirement.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->llmx->-r ./requirement.txt (line 6)) (8.1.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain->-r ./requirement.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain->-r ./requirement.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere->llmx->-r ./requirement.txt (line 6)) (3.17.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google.auth->llmx->-r ./requirement.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirement.txt (line 2)) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r ./requirement.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y02DirNRsx3C",
        "outputId": "3e96f964-1c4f-4eaa-ac56-cba3779bc93a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.348\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://github.com/langchain-ai/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, jsonpatch, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain --upgrade -q"
      ],
      "metadata": {
        "id": "kQNnMv20I4Ny"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv"
      ],
      "metadata": {
        "id": "zd2k-w4JBV1y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "load_dotenv(find_dotenv(), override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-Zcr1JHBX06",
        "outputId": "96adec8d-2457-41e4-a6bd-f40ebf9996e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "FccnVc53t6ds"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106', temperature=0.8)"
      ],
      "metadata": {
        "id": "87STy06wAwpR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are a AI Researcher\n",
        "              write the user answer about {input_question} in {language} language \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = ['input_question','language'],\n",
        "    template = template )"
      ],
      "metadata": {
        "id": "XLlDi_AABKqm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm= llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "-OmFeJx3CV7j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.run({'input_question': 'Gemini vs chatgpt', 'language': 'English'})"
      ],
      "metadata": {
        "id": "_7eC9HlICpBp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R31RVcYlDKaq",
        "outputId": "834da45a-4cff-47b5-c031-1338aea0dcaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both Gemini and ChatGPT are powerful AI models that excel in different ways. Gemini is specifically designed for natural language processing and understanding, making it a great choice for applications that require advanced language understanding capabilities. On the other hand, ChatGPT is a conversational AI model that is optimized for generating human-like responses in text-based conversations. Both models have their own strengths and weaknesses, so the choice between Gemini and ChatGPT ultimately depends on the specific requirements of the application or project at hand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#above answer looks like chatGPT is yet to update the Gemini model release and purpose... haha"
      ],
      "metadata": {
        "id": "ZILuIeiTDUyf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Sequential Chain***\n",
        "with sequential chains, we can make a series of calls to one or more LLMs. We can take the output from once chain and use it as the input to another chain.\n",
        "\n",
        "There are two types of sequential chains:\n",
        "1. SimpleSequentialChain\n",
        "2. General form of Sequential chains\n",
        "\n",
        "SimpleSequentialChain:\n",
        "it repersents a series of chians, where each individual chain has a single input and a single output, and the output of one step is used as input to the next.\n"
      ],
      "metadata": {
        "id": "ttzrMBplEyGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain"
      ],
      "metadata": {
        "id": "S-bXipZcEdjM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1 = OpenAI(model_name=\"text-davinci-003\", temperature=0.8, max_tokens=1024)\n",
        "\n",
        "prompt1=PromptTemplate(\n",
        "    input_variables=['concept'],\n",
        "    template = \"\"\" you are the experienced Data Scientist and python programmer,\n",
        "                    write the function that implements the concept of {concept}\"\"\"\n",
        ")\n",
        "\n",
        "chain1 = LLMChain(llm=llm1, prompt=prompt1)"
      ],
      "metadata": {
        "id": "DlYWzsG8GNa_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = OpenAI(model_name=\"gpt-3.5-turbo-1106\", temperature=0.8)\n",
        "\n",
        "prompt2=PromptTemplate(\n",
        "    input_variables=['function'],\n",
        "    template = \"\"\" Given the python function {function}, describe it as detailed as possible\"\"\"\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(llm=llm2, prompt=prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H9_XmJTHBGE",
        "outputId": "7ccd4654-29de-4dd0-e6f3-46ec29bbf818"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:244: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:1043: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)"
      ],
      "metadata": {
        "id": "BIFl063NHnAh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = overall_chain.run(\"SVM\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4-RKgxlH4dw",
        "outputId": "f160e9a5-6e65-4adc-f0ab-5bd391b56947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m algorithm\n",
            "\n",
            "import numpy as np\n",
            "from sklearn import svm\n",
            "\n",
            "# define the function\n",
            "def svm_function(x, y, c, gamma):\n",
            "    \"\"\"\n",
            "    Implements the concept of SVM algorithm.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    x : numpy array\n",
            "        An array of independent variables.\n",
            "    y : numpy array\n",
            "        An array of dependent variables.\n",
            "    c : float\n",
            "        The regularisation parameter.\n",
            "    gamma : float\n",
            "        The kernel coefficient.\n",
            "    \n",
            "    Returns\n",
            "    ----------\n",
            "    classifier : svm.SVC\n",
            "        The svm classifier object.\n",
            "    \"\"\"\n",
            "    \n",
            "    # create a svm classifier\n",
            "    classifier = svm.SVC(C=c, gamma=gamma)\n",
            "    \n",
            "    # fit the classifier to the data\n",
            "    classifier.fit(x, y)\n",
            "    \n",
            "    # return the classifier\n",
            "    return classifier\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3mThe `svm_function` is a Python function that implements the concept of a Support Vector Machine (SVM) algorithm. It uses the `svm` module from the `sklearn` library.\n",
            "\n",
            "Parameters:\n",
            "- `x` : numpy array\n",
            "  An array of independent variables.\n",
            "- `y` : numpy array\n",
            "  An array of dependent variables.\n",
            "- `c` : float\n",
            "  The regularisation parameter.\n",
            "- `gamma` : float\n",
            "  The kernel coefficient.\n",
            "\n",
            "Returns:\n",
            "- `classifier` : svm.SVC\n",
            "  The svm classifier object.\n",
            "\n",
            "Description:\n",
            "The function creates an SVM classifier using the `svm.SVC` class from the `sklearn` library, with the regularization parameter `C` set to the value of `c` and the kernel coefficient `gamma` set to the value of `gamma`. The `fit` method is then used to fit the classifier to the input data `x` and `y`.\n",
            "\n",
            "The trained SVM classifier object is returned as the output of the function. This classifier can be used for making predictions on new data.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xJfHsiuIN6-"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}